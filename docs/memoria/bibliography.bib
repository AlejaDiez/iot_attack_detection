@misc{iconos,
    author = {Vectorslab},
    title = {Iconos en {Flaticon}},
    url = {https://www.flaticon.es/autores/vectorslab},
    howpublished = {\url{https://www.flaticon.es/autores/vectorslab}},
}

@InProceedings{dataset,
    author = {Sarhan, Mohanad
    and Layeghy, Siamak
    and Moustafa, Nour
    and Portmann, Marius},
    editor = {Deze, Zeng
    and Huang, Huan
    and Hou, Rui
    and Rho, Seungmin
    and Chilamkurti, Naveen},
    title = {NetFlow Datasets for Machine Learning-Based Network Intrusion Detection Systems},
    booktitle = {Big Data Technologies and Applications},
    year = {2021},
    publisher = {Springer International Publishing},
    address = {Cham},
    pages = {117--135},
    abstract = {Machine Learning (ML)-based Network Intrusion Detection Systems (NIDSs) have become a promising tool to protect networks against cyberattacks. A wide range of datasets are publicly available and have been used for the development and evaluation of a large number of ML-based NIDS in the research community. However, since these NIDS datasets have very different feature sets, it is currently very difficult to reliably compare ML models across different datasets, and hence if they generalise to different network environments and attack scenarios. The limited ability to evaluate ML-based NIDSs has led to a gap between the extensive academic research conducted and the actual practical deployments in the real-world networks. This paper addresses this limitation, by providing five NIDS datasets with a common, practically relevant feature set, based on NetFlow. These datasets are generated from the following four existing benchmark NIDS datasets: UNSW-NB15, BoT-IoT, ToN-IoT, and CSE-CIC-IDS2018. We have used the raw packet capture files of these datasets, and converted them to the NetFlow format, with a common feature set. The benefits of using NetFlow as a common format include its practical relevance, its wide deployment in production networks, and its scaling properties. The generated NetFlow datasets presented in this paper have been labelled for both binary- and multi-class traffic and attack classification experiments, and we have made them available for to the research community[1]. As a use-case and application scenario, the paper presents an evaluation of an Extra Trees ensemble classifier across these datasets.},
    isbn = {978-3-030-72802-1},
}

@misc{dataset_source,
	title = {ML-Based NIDS Datasets},
	url = {https://www.itee.uq.edu.au/research/cyber-security/research-areas},
    howpublished = {\url{https://www.itee.uq.edu.au/research/cyber-security/research-areas}},
	urldate = {2025-04-28},
    note = {[Último acceso 25 de Abril de 2025]},
	journal = {School of Information Technology and Electrical Engineering},
	author = {Queensland, The University of and Lucia, Australia Brisbane St and Ipswich, QLD 4072 +61 7 3365 1111 Other Campuses: UQ and Gatton, U. Q. and Maps, UQ Herston and Queensland, Directions © 2013 The University of},
}

@misc{gicap,
    author = {GICAP},
    title = {Grupo de Inteligencia Computacional Aplicada},
    year = {2008},
    url = {https://gicap.ubu.es/main/home.shtml},
    howpublished = {\url{https://gicap.ubu.es/main/home.shtml}},
	urldate = {2025-05-06},
    note = {[Último acceso 6 de Mayo de 2025]},
}

@misc{machine_learning,
    author = {Google Cloud Tech},
	title = {¿Qué es el aprendizaje automático? Tipos y usos},
	shorttitle = {¿Qué es el aprendizaje automático?},
	url = {https://cloud.google.com/learn/what-is-machine-learning},
    howpublished = {\url{https://cloud.google.com/learn/what-is-machine-learning}},
	abstract = {El aprendizaje automático es un subconjunto de la IA que habilita el uso de redes neuronales y el aprendizaje profundo autónomo. Descubre cómo funciona el aprendizaje automático y cómo se puede usar.},
	language = {es-419},
	urldate = {2025-05-14},
    note = {[Último acceso 14 de Mayo de 2025]},
	journal = {Google Cloud},
}

@misc{aprendizaje_supervisado,
    author = {IBM},
	title = {¿Qué es el aprendizaje supervisado?},
	url = {https://www.ibm.com/es-es/topics/supervised-learning},
    howpublished = {\url{https://www.ibm.com/es-es/topics/supervised-learning}},
	abstract = {El aprendizaje supervisado es una técnica de machine learning que utiliza conjuntos de datos etiquetados para entrenar modelos de algoritmos de inteligencia artificial para identificar los patrones subyacentes y las relaciones entre las características de entrada y salida. El objetivo del proceso de aprendizaje es crear un modelo que pueda predecir resultados correctos en nuevos datos del mundo real.},
	language = {es-es},
	urldate = {2025-05-14},
    note = {[Último acceso 14 de Mayo de 2025]},
	month = dec,
	year = {2024},
}

@misc{aprendizaje_federado_introduccion,
	title = {Introduction to Federated Learning and Challenges},
	url = {https://towardsdatascience.com/introduction-to-federated-learning-and-challenges-ea7e02f260ca/},
    howpublished = {\url{https://towardsdatascience.com/introduction-to-federated-learning-and-challenges-ea7e02f260ca/}},
	abstract = {Introduction},
	language = {en-US},
	urldate = {2025-01-28},
    note = {[Último acceso 28 de Enero de 2025]},
	journal = {Towards Data Science},
	author = {Kelvin},
	month = oct,
	year = {2020},
}

@misc{aprendizaje_federado_comic,
	author = {Google Cloud Tech},
	title = {Federated Learning},
	url = {https://federated.withgoogle.com},
    howpublished = {\url{https://federated.withgoogle.com}},
	abstract = {Building better products with on-device data and privacy by default. An online comic from Google AI.},
	language = {en},
	urldate = {2025-01-20},
    note = {[Último acceso 20 de Enero de 2025]},
	journal = {Federated Learning},
}

@misc{aprendizaje_federado_video,
	title = {What is Federated Learning?},
	url = {https://www.youtube.com/watch?v=X8YYWunttOY},
    howpublished = {\url{https://www.youtube.com/watch?v=X8YYWunttOY}},
	urldate = {2025-02-19},
    note = {[Último acceso 19 de Febrero de 2025]},
	author = {Google Cloud Tech},
	month = feb,
	year = {2021},
}

@misc{aprendizaje_federado_articulo,
	title = {Communication-Efficient Learning of Deep Networks from Decentralized Data},
	url = {http://arxiv.org/abs/1602.05629},
    howpublished = {\url{http://arxiv.org/abs/1602.05629}},
	doi = {10.48550/arXiv.1602.05629},
	abstract = {Modern mobile devices have access to a wealth of data suitable for learning models, which in turn can greatly improve the user experience on the device. For example, language models can improve speech recognition and text entry, and image models can automatically select good photos. However, this rich data is often privacy sensitive, large in quantity, or both, which may preclude logging to the data center and training there using conventional approaches. We advocate an alternative that leaves the training data distributed on the mobile devices, and learns a shared model by aggregating locally-computed updates. We term this decentralized approach Federated Learning. We present a practical method for the federated learning of deep networks based on iterative model averaging, and conduct an extensive empirical evaluation, considering five different model architectures and four datasets. These experiments demonstrate the approach is robust to the unbalanced and non-IID data distributions that are a defining characteristic of this setting. Communication costs are the principal constraint, and we show a reduction in required communication rounds by 10-100x as compared to synchronized stochastic gradient descent.},
	urldate = {2025-04-12},
    note = {[Último acceso 12 de Abril de 2025]},
	publisher = {arXiv},
	author = {McMahan, H. Brendan and Moore, Eider and Ramage, Daniel and Hampson, Seth and Arcas, Blaise Agüera y},
	month = jan,
	year = {2023},
	note = {arXiv:1602.05629 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@misc{perceptron_multicapa,
	title = {Multilayer {Perceptron} {Explained} with a {Real}-{Life} {Example} and {Python} {Code}: {Sentiment} {Analysis}},
	shorttitle = {Multilayer {Perceptron} {Explained} with a {Real}-{Life} {Example} and {Python} {Code}},
	url = {https://medium.com/data-science/multilayer-perceptron-explained-with-a-real-life-example-and-python-code-sentiment-analysis-cb408ee93141},
    howpublished = {\url{https://medium.com/data-science/multilayer-perceptron-explained-with-a-real-life-example-and-python-code-sentiment-analysis-cb408ee93141}},
	abstract = {Multilayer Perceptron is a Neural Network that learns the relationship between linear and non-linear data.},
	language = {en},
	urldate = {2025-05-19},
    note = {[Último acceso 19 de Mayo de 2025]},
	journal = {TDS Archive},
	author = {Bento, Carolina},
	month = sep,
	year = {2021}
}

@misc{metricas,
	title = {Classification: {Accuracy}, recall, precision, and related metrics {\textbar} {Machine} {Learning} {\textbar} {Google} for {Developers}},
	shorttitle = {Classification},
	url = {https://developers.google.com/machine-learning/crash-course/classification/accuracy-precision-recall},
    howpublished = {\url{https://developers.google.com/machine-learning/crash-course/classification/accuracy-precision-recall}},
	abstract = {Learn how to calculate three key classification metrics—accuracy, precision, recall—and how to choose the appropriate metric to evaluate a given binary classification model.},
	language = {en},
	urldate = {2025-05-09},
    note = {[Último acceso 9 de Mayo de 2025]},
}

@misc{perdida,
	title = {Linear regression: {Loss} {\textbar} {Machine} {Learning} {\textbar} {Google} for {Developers}},
	shorttitle = {Linear regression},
	url = {https://developers.google.com/machine-learning/crash-course/linear-regression/loss},
    howpublished = {\url{https://developers.google.com/machine-learning/crash-course/linear-regression/loss}},
	abstract = {Learn different methods for how machine learning models quantify \&\#39;loss\&\#39;, the magnitude of their prediction errors. This page explains common loss metrics, including mean squared error (MSE), mean absolute error (MAE) and L1 and L2 loss.},
	language = {en},
	urldate = {2025-05-09},
    note = {[Último acceso 9 de Mayo de 2025]},
}

@misc{roc,
	title = {Classification: {ROC} and {AUC} {\textbar} {Machine} {Learning} {\textbar} {Google} for {Developers}},
	shorttitle = {Classification},
	url = {https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc},
    howpublished = {\url{https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc}},
	abstract = {Learn how to interpret an ROC curve and its AUC value to evaluate a binary classification model over all possible classification thresholds.},
	language = {en},
	urldate = {2025-05-09},
    note = {[Último acceso 9 de Mayo de 2025]},
}

@misc{matriz,
	title = {Thresholds and the confusion matrix {\textbar} {Machine} {Learning} {\textbar} {Google} for {Developers}},
	url = {https://developers.google.com/machine-learning/crash-course/classification/thresholding},
    howpublished = {\url{https://developers.google.com/machine-learning/crash-course/classification/thresholding}},
	abstract = {Learn how a classification threshold can be set to convert a logistic regression model into a binary classification model, and how to use a confusion matrix to assess the four types of predictions: true positive (TP), true negative (TN), false positive (FP), and false negative (FN).},
	language = {en},
	urldate = {2025-05-09},
    note = {[Último acceso 9 de Mayo de 2025]},
}

@misc{modelo_osi,
	title = {¿Qué es el modelo OSI?},
    author = {Cloudflare},
	url = {https://www.cloudflare.com/es-es/learning/ddos/glossary/open-systems-interconnection-model-osi/},
    howpublished = {\url{https://www.cloudflare.com/es-es/learning/ddos/glossary/open-systems-interconnection-model-osi/}},
	abstract = {¿Qué es el modelo OSI? El modelo OSI es un enfoque por capas que ayuda a estandarizar los procedimientos de gestión de datos. Ejemplos del modelo OSI aquí.},
	language = {es-es},
	urldate = {2025-05-20},
    note = {[Último acceso 20 de Mayo de 2025]},
}

@misc{ataques,
	title = {¿Qué es un ciberataque y los tipos de ataques en la red?},
    author = {Fortinet},
	url = {https://www.fortinet.com/lat/resources/cyberglossary/types-of-cyber-attacks.html},
    howpublished = {\url{https://www.fortinet.com/lat/resources/cyberglossary/types-of-cyber-attacks.html}},
	language = {es},
	urldate = {2025-05-20},
    note = {[Último acceso 20 de Mayo de 2025]},
	journal = {Fortinet},
}


@misc{ataque_dos,
	title = {Ataque de denegación de Servicio},
    author = {Cloudflare},
    url = {https://www.cloudflare.com/es-es/learning/ddos/glossary/denial-of-service/},
    howpublished = {\url{https://www.cloudflare.com/es-es/learning/ddos/glossary/denial-of-service/}},
	urldate = {2025-05-20},
    note = {[Último acceso 20 de Mayo de 2025]},
}

@misc{tensorflow_federated_tutorial,
	title = {TensorFlow Federated Tutorial Session},
    author = {Google TechTalks},
	language = {en-US},
	url = {https://www.youtube.com/watch?v=JBNas6Yd30A},
    howpublished = {\url{https://www.youtube.com/watch?v=JBNas6Yd30A}},
	urldate = {2025-02-24},
    note = {[Último acceso 24 de Febrero de 2025]},
}

@misc{tensorflow,
	title = {TensorFlow},
	url = {https://www.tensorflow.org/api_docs/python/tf},
	howpublished = {\url{https://www.tensorflow.org/api_docs/python/tf}},
	abstract = {The TensorFlow library.},
	language = {en},
	urldate = {2025-03-12},
    note = {[Último acceso 12 de Marzo de 2025]},
}

@misc{tensorflowjs,
	title = {TensorFlow.js},
	url = {https://js.tensorflow.org/api/latest/},
	howpublished = {\url{https://js.tensorflow.org/api/latest/}},
	abstract = {The TensorFlow.js library.},
	language = {en},
	urldate = {2025-04-28},
    note = {[Último acceso 28 de Abril de 2025]},
}

@misc{open_source_frameworks,
	title = {Top 7 {Open}-{Source} {Frameworks} for {Federated} {Learning}},
	url = {https://www.apheris.com/resources/blog/top-7-open-source-frameworks-for-federated-learning},
	howpublished = {\url{https://www.apheris.com/resources/blog/top-7-open-source-frameworks-for-federated-learning}},
	abstract = {Build and evolve globally impactful data ecosystems across organizations, industries, and boundaries — all while protecting privacy and IP.},
	language = {en},
	urldate = {2025-02-04},
	journal = {Apheris},
	month = sep,
	year = {2024},
    note = {[Último acceso 4 de Febrero de 2025]},
}

@misc{tensorflow_federated,
	title = {{TensorFlow} {Federated}},
	url = {https://www.tensorflow.org/federated/api_docs/python/tff},
	howpublished = {\url{https://www.tensorflow.org/federated/api_docs/python/tff}},
	abstract = {The TensorFlow Federated library.},
	language = {en},
	urldate = {2025-03-12},
    note = {[Último acceso 12 de Marzo de 2025]},
}

@misc{flower,
	title = {Flower},
	url = {https://flower.ai/docs/},
	howpublished = {\url{https://flower.ai/docs/}},
	language = {en-GB},
	urldate = {2025-03-14},
    note = {[Último acceso 14 de Marzo de 2025]},
}

@misc{angular,
	title = {Angular Moderno},
	url = {https://cursos.devtalles.com/courses/angular-moderno},
	howpublished = {\url{https://cursos.devtalles.com/courses/angular-moderno}},
	language = {es-ES},
	urldate = {2025-06-01},
    note = {[Último acceso 1 de Junio de 2025]},
}

@misc{flujo_paquetes,
	title = {Gestión de recursos de red mediante flujos},
	url = {https://docs.oracle.com/cd/E56339_01/html/E53790/gitiz.html#scrolltoc},
	urldate = {2025-06-05},
    howpublished = {\url{https://docs.oracle.com/cd/E56339_01/html/E53790/gitiz.html#scrolltoc}},
	urldate = {2025-06-05},
    note = {[Último acceso 5 de Junio de 2025]},
}

